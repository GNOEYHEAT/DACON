{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uO10XRn3dn1L"
   },
   "source": [
    "# Baseline (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1655180838758,
     "user": {
      "displayName": "‍김태형[ 대학원석·박사통합과정재학 / 산업경영공학과 ]",
      "userId": "00288066936238655028"
     },
     "user_tz": -540
    },
    "id": "qlG--rMUIhtl",
    "outputId": "ae8c4164-a38a-469d-9365-ca22d43833e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgnoeyheat\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Taehyeong\\_DACON\\DACON_235910\\wandb\\run-20220621_234953-1f64dk47</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gnoeyheat/DACON_235910/runs/1f64dk47\" target=\"_blank\">Baseline_T</a></strong> to <a href=\"https://wandb.ai/gnoeyheat/DACON_235910\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>respiratory_condition</th>\n",
       "      <th>fever_or_muscle_pain</th>\n",
       "      <th>covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2.7372453e-09, -1.0615647e-08, 5.2142607e-08,...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  id  age  gender  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   1   24  female   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   2   51    male   \n",
       "2  [2.7372453e-09, -1.0615647e-08, 5.2142607e-08,...   3   22    male   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   4   29  female   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   5   23    male   \n",
       "\n",
       "   respiratory_condition  fever_or_muscle_pain  covid19  \n",
       "0                      0                     1        0  \n",
       "1                      0                     0        0  \n",
       "2                      0                     0        0  \n",
       "3                      1                     0        0  \n",
       "4                      0                     0        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras import layers\n",
    "\n",
    "import librosa\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, OneOf\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"DACON_235910\", name=\"Baseline_T\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Baseline_T\")\n",
    "parser.add_argument('--sampling_rate', default=16000, type=int)\n",
    "parser.add_argument('--augmentation', default=True, type=bool)\n",
    "parser.add_argument('--optimizer', default=\"sgd\", type=str) # sgd or adam\n",
    "parser.add_argument('--loss', default=\"fl\", type=str) # bc or fl\n",
    "parser.add_argument('--learning_rate', default=0.001, type=float)\n",
    "parser.add_argument('--batch_size', default=32, type=int)\n",
    "parser.add_argument('--epochs', default=100, type=int)\n",
    "parser.add_argument('--cv', default=10, type=int)\n",
    "parser.add_argument('--seed', default=1011, type=int)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "wandb.config.update(args)\n",
    "\n",
    "sampling_rate = args.sampling_rate\n",
    "augmentation = args.augmentation\n",
    "optimizer = args.optimizer\n",
    "loss = args.loss\n",
    "learning_rate = args.learning_rate\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.epochs\n",
    "cv = args.cv\n",
    "seed = args.seed\n",
    "\n",
    "def set_seeds(seed=seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "augment = Compose([\n",
    "    OneOf([\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "    ])\n",
    "])\n",
    "\n",
    "with open('data/train_df.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "with open('data/test_df.pkl', 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"data/train_data.csv\")\n",
    "# test_df = pd.read_csv(\"data/test_data.csv\")\n",
    "\n",
    "# train_folder = \"data/train/\"\n",
    "# test_folder = \"data/test/\"\n",
    "\n",
    "# def dataset(folder, df):\n",
    "#     dataset = []\n",
    "#     for uid in tqdm(df['id']):\n",
    "#         path = os.path.join(folder, str(uid).zfill(5)+'.wav')\n",
    "#         y, sr = librosa.load(path, sr=sampling_rate)\n",
    "#         y = librosa.util.normalize(y)\n",
    "#         dataset.append([y])\n",
    "#     dataset = pd.DataFrame(dataset, columns=['data'])\n",
    "#     dataset = pd.concat([dataset, df], axis=1)\n",
    "#     return dataset\n",
    "\n",
    "# train_df = dataset(train_folder, train_df)\n",
    "# test_df = dataset(test_folder, test_df)\n",
    "\n",
    "# with open('train_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "# with open('test_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLr-znikdl4b"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156480.0, 155520.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"len\"] = train_df[\"data\"].apply(lambda x : len(x))\n",
    "test_df[\"len\"] = test_df[\"data\"].apply(lambda x : len(x))\n",
    "\n",
    "train_df[\"len\"].median(), test_df[\"len\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3805, 150000, 1), (3805,), (5732, 150000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(train_df[\"data\"],\n",
    "                                                  maxlen=150000,\n",
    "                                                  dtype=\"float32\")[:, :, np.newaxis]\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(test_df[\"data\"],\n",
    "                                                       maxlen=150000,\n",
    "                                                       dtype=\"float32\")[:, :, np.newaxis]\n",
    "if augmentation == True:\n",
    "    X = augment(samples=X, sample_rate=sampling_rate)\n",
    "\n",
    "y = train_df[\"covid19\"]\n",
    "\n",
    "X.shape, y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5732, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_feature(df):\n",
    "    temp = df.copy()\n",
    "    temp[\"condition1\"] = temp[\"respiratory_condition\"] + temp[\"fever_or_muscle_pain\"]\n",
    "    temp[\"condition2\"] = temp[\"respiratory_condition\"] * temp[\"fever_or_muscle_pain\"]\n",
    "    temp = temp.drop([\"id\", \"age\", \"gender\", \"respiratory_condition\", \"fever_or_muscle_pain\"], axis=1)\n",
    "    return temp\n",
    "\n",
    "train_df = preprocess_feature(train_df)\n",
    "test_df = preprocess_feature(test_df)\n",
    "\n",
    "X_test_tab = test_df[[\"condition1\", \"condition2\"]].values\n",
    "\n",
    "X_test_tab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mtlHyQhgAoN"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150000, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 37500, 16)    160         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 37500, 16)   64          ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 37500, 16)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 9375, 16)     2320        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 9375, 16)    64          ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 3125, 32)     4128        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 3125, 32)    128         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 3125, 32)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 1042, 32)     8224        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 1042, 32)    128         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 348, 64)      14400       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 348, 64)     256         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 348, 64)      0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 116, 64)      28736       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 116, 64)     256         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 116, 64)      0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 58, 128)      49280       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 58, 128)     512         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 58, 128)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 29, 128)      98432       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 29, 128)     512         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 29, 128)      0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 15, 256)      164096      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 15, 256)     1024        ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 15, 256)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 8, 256)       327936      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 256)      1024        ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 8, 512)       524800      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 512)      2048        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 8, 512)       0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 8, 512)       1049088     ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 512)      2048        ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 8, 512)       0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 8, 1024)      1573888     ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 8, 1024)     4096        ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 8, 1024)      0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 8, 1024)      3146752     ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 1024)     4096        ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8, 1024)      0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 1024)        0           ['activation_10[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1026)         0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'input_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          262912      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           16448       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           1040        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            17          ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,288,913\n",
      "Trainable params: 7,280,785\n",
      "Non-trainable params: 8,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def scratch_1dcnn():\n",
    "    \n",
    "    inp = tf.keras.Input(shape=(X.shape[1], X.shape[2]))\n",
    "    tab = tf.keras.Input(shape=(X_test_tab.shape[1],))\n",
    "    \n",
    "    x = layers.Conv1D(16, 9, 4, padding=\"same\")(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv1D(16, 9, 4, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv1D(32, 8, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv1D(32, 8, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv1D(64, 7, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv1D(64, 7, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv1D(128, 6, 2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv1D(128, 6, 2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv1D(256, 5, 2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv1D(256, 5, 2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv1D(512, 4, 1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv1D(512, 4, 1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv1D(1024, 3, 1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv1D(1024, 3, 1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Concatenate()([x, tab])\n",
    "    \n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    oup = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inp, tab], outputs=oup)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = scratch_1dcnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhXTtjxTTlss",
    "outputId": "7ca4889d-0322-4d75-ae76-33a37b41f868"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 33s 100ms/step - loss: 0.0355 - val_loss: 0.0421 - _timestamp: 1655823059.0000 - _runtime: 66.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.0288 - val_loss: 0.0294 - _timestamp: 1655823071.0000 - _runtime: 78.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0263 - val_loss: 0.0335 - _timestamp: 1655823082.0000 - _runtime: 89.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0222 - val_loss: 0.0343 - _timestamp: 1655823092.0000 - _runtime: 99.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0167 - val_loss: 0.0334 - _timestamp: 1655823102.0000 - _runtime: 109.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0119 - val_loss: 0.0477 - _timestamp: 1655823112.0000 - _runtime: 119.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0085 - val_loss: 0.0451 - _timestamp: 1655823122.0000 - _runtime: 129.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0056 - val_loss: 0.0516 - _timestamp: 1655823132.0000 - _runtime: 139.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 8s 79ms/step - loss: 0.0043 - val_loss: 0.0549 - _timestamp: 1655823142.0000 - _runtime: 149.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0044 - val_loss: 0.0560 - _timestamp: 1655823153.0000 - _runtime: 160.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0042 - val_loss: 0.0563 - _timestamp: 1655823163.0000 - _runtime: 170.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0043 - val_loss: 0.0565 - _timestamp: 1655823173.0000 - _runtime: 180.0000\n",
      "idx:1, f1:0.478796169630643, threshold:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:54, 174.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 14s 90ms/step - loss: 0.0328 - val_loss: 0.0388 - _timestamp: 1655823213.0000 - _runtime: 220.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0282 - val_loss: 0.0323 - _timestamp: 1655823224.0000 - _runtime: 231.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 10s 98ms/step - loss: 0.0253 - val_loss: 0.0294 - _timestamp: 1655823235.0000 - _runtime: 242.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 9s 86ms/step - loss: 0.0196 - val_loss: 0.0287 - _timestamp: 1655823246.0000 - _runtime: 253.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0146 - val_loss: 0.0301 - _timestamp: 1655823256.0000 - _runtime: 263.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0098 - val_loss: 0.0385 - _timestamp: 1655823266.0000 - _runtime: 273.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 8s 79ms/step - loss: 0.0067 - val_loss: 0.0525 - _timestamp: 1655823276.0000 - _runtime: 283.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0052 - val_loss: 0.0508 - _timestamp: 1655823286.0000 - _runtime: 293.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0044 - val_loss: 0.0564 - _timestamp: 1655823296.0000 - _runtime: 303.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 8s 79ms/step - loss: 0.0042 - val_loss: 0.0575 - _timestamp: 1655823306.0000 - _runtime: 313.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 9s 79ms/step - loss: 0.0045 - val_loss: 0.0580 - _timestamp: 1655823316.0000 - _runtime: 323.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0044 - val_loss: 0.0578 - _timestamp: 1655823326.0000 - _runtime: 333.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0042 - val_loss: 0.0577 - _timestamp: 1655823336.0000 - _runtime: 343.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0041 - val_loss: 0.0577 - _timestamp: 1655823346.0000 - _runtime: 353.0000\n",
      "idx:2, f1:0.6412429378531074, threshold:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [05:46, 173.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 14s 94ms/step - loss: 0.0350 - val_loss: 0.0326 - _timestamp: 1655823385.0000 - _runtime: 392.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 9s 87ms/step - loss: 0.0287 - val_loss: 0.0290 - _timestamp: 1655823396.0000 - _runtime: 403.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 10s 90ms/step - loss: 0.0260 - val_loss: 0.0280 - _timestamp: 1655823406.0000 - _runtime: 413.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 10s 89ms/step - loss: 0.0226 - val_loss: 0.0268 - _timestamp: 1655823417.0000 - _runtime: 424.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0171 - val_loss: 0.0272 - _timestamp: 1655823428.0000 - _runtime: 435.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0120 - val_loss: 0.0329 - _timestamp: 1655823438.0000 - _runtime: 445.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0077 - val_loss: 0.0418 - _timestamp: 1655823448.0000 - _runtime: 455.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0056 - val_loss: 0.0494 - _timestamp: 1655823459.0000 - _runtime: 466.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0047 - val_loss: 0.0494 - _timestamp: 1655823469.0000 - _runtime: 476.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0042 - val_loss: 0.0513 - _timestamp: 1655823479.0000 - _runtime: 486.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0041 - val_loss: 0.0521 - _timestamp: 1655823490.0000 - _runtime: 497.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0044 - val_loss: 0.0524 - _timestamp: 1655823500.0000 - _runtime: 507.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0046 - val_loss: 0.0524 - _timestamp: 1655823510.0000 - _runtime: 517.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0044 - val_loss: 0.0524 - _timestamp: 1655823520.0000 - _runtime: 527.0000\n",
      "idx:3, f1:0.4862459546925566, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [08:40, 173.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 14s 89ms/step - loss: 0.0376 - val_loss: 0.0339 - _timestamp: 1655823560.0000 - _runtime: 567.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0280 - val_loss: 0.0287 - _timestamp: 1655823570.0000 - _runtime: 577.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 9s 84ms/step - loss: 0.0265 - val_loss: 0.0278 - _timestamp: 1655823580.0000 - _runtime: 587.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.0256 - val_loss: 0.0273 - _timestamp: 1655823592.0000 - _runtime: 599.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 8s 79ms/step - loss: 0.0235 - val_loss: 0.0282 - _timestamp: 1655823602.0000 - _runtime: 609.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 9s 79ms/step - loss: 0.0195 - val_loss: 0.0320 - _timestamp: 1655823612.0000 - _runtime: 619.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 8s 78ms/step - loss: 0.0162 - val_loss: 0.0397 - _timestamp: 1655823621.0000 - _runtime: 628.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 8s 79ms/step - loss: 0.0138 - val_loss: 0.0433 - _timestamp: 1655823631.0000 - _runtime: 638.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0123 - val_loss: 0.0442 - _timestamp: 1655823642.0000 - _runtime: 649.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 8s 79ms/step - loss: 0.0123 - val_loss: 0.0450 - _timestamp: 1655823651.0000 - _runtime: 658.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 9s 79ms/step - loss: 0.0116 - val_loss: 0.0453 - _timestamp: 1655823661.0000 - _runtime: 668.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 9s 80ms/step - loss: 0.0118 - val_loss: 0.0454 - _timestamp: 1655823671.0000 - _runtime: 678.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0119 - val_loss: 0.0452 - _timestamp: 1655823682.0000 - _runtime: 689.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0118 - val_loss: 0.0451 - _timestamp: 1655823692.0000 - _runtime: 699.0000\n",
      "idx:4, f1:0.5902208984859767, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [11:32, 172.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 14s 99ms/step - loss: 0.0360 - val_loss: 0.0406 - _timestamp: 1655823731.0000 - _runtime: 738.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 9s 87ms/step - loss: 0.0285 - val_loss: 0.0318 - _timestamp: 1655823742.0000 - _runtime: 749.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 9s 88ms/step - loss: 0.0258 - val_loss: 0.0277 - _timestamp: 1655823753.0000 - _runtime: 760.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0219 - val_loss: 0.0278 - _timestamp: 1655823763.0000 - _runtime: 770.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0175 - val_loss: 0.0316 - _timestamp: 1655823773.0000 - _runtime: 780.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0121 - val_loss: 0.0376 - _timestamp: 1655823784.0000 - _runtime: 791.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0086 - val_loss: 0.0638 - _timestamp: 1655823794.0000 - _runtime: 801.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0068 - val_loss: 0.0574 - _timestamp: 1655823804.0000 - _runtime: 811.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0060 - val_loss: 0.0643 - _timestamp: 1655823814.0000 - _runtime: 821.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0059 - val_loss: 0.0647 - _timestamp: 1655823825.0000 - _runtime: 832.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 9s 82ms/step - loss: 0.0059 - val_loss: 0.0649 - _timestamp: 1655823835.0000 - _runtime: 842.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 9s 81ms/step - loss: 0.0055 - val_loss: 0.0649 - _timestamp: 1655823845.0000 - _runtime: 852.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 9s 83ms/step - loss: 0.0055 - val_loss: 0.0651 - _timestamp: 1655823855.0000 - _runtime: 862.0000\n",
      "idx:5, f1:0.478796169630643, threshold:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [14:16, 169.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 15s 105ms/step - loss: 0.0356 - val_loss: 0.0476 - _timestamp: 1655823896.0000 - _runtime: 903.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 9s 85ms/step - loss: 0.0288 - val_loss: 0.0291 - _timestamp: 1655823906.0000 - _runtime: 913.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0242 - val_loss: 0.0302 - _timestamp: 1655823916.0000 - _runtime: 923.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 9s 86ms/step - loss: 0.0204 - val_loss: 0.0285 - _timestamp: 1655823927.0000 - _runtime: 934.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0168 - val_loss: 0.0389 - _timestamp: 1655823937.0000 - _runtime: 944.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0111 - val_loss: 0.0590 - _timestamp: 1655823948.0000 - _runtime: 955.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0069 - val_loss: 0.0756 - _timestamp: 1655823958.0000 - _runtime: 965.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0053 - val_loss: 0.0635 - _timestamp: 1655823968.0000 - _runtime: 975.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0042 - val_loss: 0.0684 - _timestamp: 1655823978.0000 - _runtime: 985.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0042 - val_loss: 0.0687 - _timestamp: 1655823988.0000 - _runtime: 995.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0040 - val_loss: 0.0684 - _timestamp: 1655823998.0000 - _runtime: 1005.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0042 - val_loss: 0.0684 - _timestamp: 1655824009.0000 - _runtime: 1016.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0040 - val_loss: 0.0683 - _timestamp: 1655824019.0000 - _runtime: 1026.0000\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0036 - val_loss: 0.0683 - _timestamp: 1655824029.0000 - _runtime: 1036.0000\n",
      "idx:6, f1:0.5283003659460592, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [17:09, 170.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 13s 93ms/step - loss: 0.0336 - val_loss: 0.0356 - _timestamp: 1655824068.0000 - _runtime: 1075.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 9s 87ms/step - loss: 0.0289 - val_loss: 0.0300 - _timestamp: 1655824078.0000 - _runtime: 1085.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.0262 - val_loss: 0.0285 - _timestamp: 1655824091.0000 - _runtime: 1098.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0222 - val_loss: 0.0312 - _timestamp: 1655824101.0000 - _runtime: 1108.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0172 - val_loss: 0.0303 - _timestamp: 1655824112.0000 - _runtime: 1119.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 9s 85ms/step - loss: 0.0117 - val_loss: 0.0364 - _timestamp: 1655824122.0000 - _runtime: 1129.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0063 - val_loss: 0.0568 - _timestamp: 1655824133.0000 - _runtime: 1140.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0045 - val_loss: 0.0564 - _timestamp: 1655824143.0000 - _runtime: 1150.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0036 - val_loss: 0.0564 - _timestamp: 1655824153.0000 - _runtime: 1160.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0034 - val_loss: 0.0572 - _timestamp: 1655824164.0000 - _runtime: 1171.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.0033 - val_loss: 0.0580 - _timestamp: 1655824175.0000 - _runtime: 1182.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0034 - val_loss: 0.0585 - _timestamp: 1655824185.0000 - _runtime: 1192.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0035 - val_loss: 0.0579 - _timestamp: 1655824196.0000 - _runtime: 1203.0000\n",
      "idx:7, f1:0.6351221593940041, threshold:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [19:57, 169.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 13s 92ms/step - loss: 0.0373 - val_loss: 0.0289 - _timestamp: 1655824235.0000 - _runtime: 1242.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 10s 89ms/step - loss: 0.0281 - val_loss: 0.0257 - _timestamp: 1655824246.0000 - _runtime: 1253.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0268 - val_loss: 0.0278 - _timestamp: 1655824256.0000 - _runtime: 1263.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0248 - val_loss: 0.0258 - _timestamp: 1655824266.0000 - _runtime: 1273.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0222 - val_loss: 0.0267 - _timestamp: 1655824276.0000 - _runtime: 1283.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0179 - val_loss: 0.0298 - _timestamp: 1655824287.0000 - _runtime: 1294.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0134 - val_loss: 0.0373 - _timestamp: 1655824297.0000 - _runtime: 1304.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0106 - val_loss: 0.0375 - _timestamp: 1655824307.0000 - _runtime: 1314.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0090 - val_loss: 0.0382 - _timestamp: 1655824317.0000 - _runtime: 1324.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0093 - val_loss: 0.0388 - _timestamp: 1655824328.0000 - _runtime: 1335.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0090 - val_loss: 0.0391 - _timestamp: 1655824338.0000 - _runtime: 1345.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.0087 - val_loss: 0.0389 - _timestamp: 1655824348.0000 - _runtime: 1355.0000\n",
      "idx:8, f1:0.4794520547945205, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [22:30, 164.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 13s 89ms/step - loss: 0.0370 - val_loss: 0.0368 - _timestamp: 1655824388.0000 - _runtime: 1395.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.0288 - val_loss: 0.0311 - _timestamp: 1655824399.0000 - _runtime: 1406.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 9s 86ms/step - loss: 0.0252 - val_loss: 0.0298 - _timestamp: 1655824409.0000 - _runtime: 1416.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 9s 85ms/step - loss: 0.0206 - val_loss: 0.0270 - _timestamp: 1655824420.0000 - _runtime: 1427.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0162 - val_loss: 0.0329 - _timestamp: 1655824430.0000 - _runtime: 1437.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0119 - val_loss: 0.0385 - _timestamp: 1655824440.0000 - _runtime: 1447.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0074 - val_loss: 0.0464 - _timestamp: 1655824450.0000 - _runtime: 1457.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0052 - val_loss: 0.0614 - _timestamp: 1655824460.0000 - _runtime: 1467.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0047 - val_loss: 0.0632 - _timestamp: 1655824470.0000 - _runtime: 1477.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0042 - val_loss: 0.0646 - _timestamp: 1655824480.0000 - _runtime: 1487.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0041 - val_loss: 0.0650 - _timestamp: 1655824490.0000 - _runtime: 1497.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0045 - val_loss: 0.0653 - _timestamp: 1655824500.0000 - _runtime: 1507.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0039 - val_loss: 0.0650 - _timestamp: 1655824510.0000 - _runtime: 1517.0000\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0044 - val_loss: 0.0650 - _timestamp: 1655824520.0000 - _runtime: 1527.0000\n",
      "idx:9, f1:0.4850521308664509, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [25:21, 166.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 13s 87ms/step - loss: 0.0362 - val_loss: 0.0403 - _timestamp: 1655824558.0000 - _runtime: 1565.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 9s 83ms/step - loss: 0.0279 - val_loss: 0.0288 - _timestamp: 1655824569.0000 - _runtime: 1576.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 8s 78ms/step - loss: 0.0254 - val_loss: 0.0289 - _timestamp: 1655824579.0000 - _runtime: 1586.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.0201 - val_loss: 0.0270 - _timestamp: 1655824589.0000 - _runtime: 1596.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0158 - val_loss: 0.0278 - _timestamp: 1655824599.0000 - _runtime: 1606.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0105 - val_loss: 0.0368 - _timestamp: 1655824609.0000 - _runtime: 1616.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0074 - val_loss: 0.0397 - _timestamp: 1655824619.0000 - _runtime: 1626.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0053 - val_loss: 0.0441 - _timestamp: 1655824629.0000 - _runtime: 1636.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0040 - val_loss: 0.0496 - _timestamp: 1655824639.0000 - _runtime: 1646.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0042 - val_loss: 0.0499 - _timestamp: 1655824649.0000 - _runtime: 1656.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0040 - val_loss: 0.0498 - _timestamp: 1655824659.0000 - _runtime: 1666.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0041 - val_loss: 0.0498 - _timestamp: 1655824669.0000 - _runtime: 1676.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.0040 - val_loss: 0.0497 - _timestamp: 1655824680.0000 - _runtime: 1687.0000\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.0041 - val_loss: 0.0501 - _timestamp: 1655824690.0000 - _runtime: 1697.0000\n",
      "idx:10, f1:0.5459236326109391, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [28:12, 169.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_macro-f1:  0.5349152473904899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validations = []\n",
    "thresholds = []\n",
    "predictions = []\n",
    "\n",
    "idx=0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cv)\n",
    "for train_index, val_index in tqdm(skf.split(X, y)):\n",
    "    \n",
    "    idx+=1\n",
    "\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train_tab = train_df[[\"condition1\", \"condition2\"]].values[train_index]\n",
    "    X_val_tab = train_df[[\"condition1\", \"condition2\"]].values[val_index]\n",
    "    \n",
    "    train_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(((X_train, X_train_tab), y_train))\n",
    "        .shuffle(len(X_train))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    val_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(((X_val, X_val_tab), y_val))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    model = scratch_1dcnn()\n",
    "\n",
    "    lr = tf.keras.optimizers.schedules.CosineDecay(learning_rate, decay_steps=1000)\n",
    "    if optimizer == \"adam\":\n",
    "        optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optim = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "        \n",
    "    if loss == \"bc\":\n",
    "        label_smoothing=0\n",
    "        loss_function = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
    "    elif loss == \"fl\":\n",
    "        loss_function = tfa.losses.SigmoidFocalCrossEntropy()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optim,\n",
    "        loss=loss_function,\n",
    "    )\n",
    "    \n",
    "    checkpoint_filepath=f\"load_model/{parser.description}_{idx}\"\n",
    "\n",
    "    checkpoint_callback = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint_callback, WandbCallback()],\n",
    "    )\n",
    "\n",
    "    max_f1 = 0\n",
    "    threshold = 0\n",
    "    for temp_threshold in np.linspace(0.05, 0.95, 19):\n",
    "        temp_f1 = f1_score(y_val, np.where(model.predict(val_ds)>temp_threshold, 1, 0), average=\"macro\")\n",
    "        if temp_f1 > max_f1:\n",
    "            max_f1 = temp_f1\n",
    "            threshold = temp_threshold\n",
    "    \n",
    "    print(f\"idx:{idx}, f1:{max_f1}, threshold:{threshold}\")\n",
    "    \n",
    "    validations.append(max_f1)\n",
    "    thresholds.append(threshold)\n",
    "    predictions.append(model.predict([X_test, X_test_tab]))\n",
    "\n",
    "val_f1 = np.mean(validations, axis=0)\n",
    "\n",
    "print(\"validation_macro-f1: \", val_f1)\n",
    "wandb.log({'validation_macro-f1': val_f1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7vNprtvVIb0"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Rb1j87j7k3l9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.964061\n",
       "1    0.035939\n",
       "Name: covid19, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = np.mean(thresholds)\n",
    "test_df[\"covid19\"] = np.where(np.mean(predictions, axis=0)>threshold, 1, 0)\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['covid19'] = test_df['covid19']\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "test_df['covid19'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOI2a3K41SRHmr0VYqCJIVd",
   "collapsed_sections": [],
   "mount_file_id": "12SyNXKXsgbk5c855KhTFRgLEogv2xCNZ",
   "name": "2. Baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
