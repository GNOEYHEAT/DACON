{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uO10XRn3dn1L"
   },
   "source": [
    "# cRT (T-F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1655180838758,
     "user": {
      "displayName": "‍김태형[ 대학원석·박사통합과정재학 / 산업경영공학과 ]",
      "userId": "00288066936238655028"
     },
     "user_tz": -540
    },
    "id": "qlG--rMUIhtl",
    "outputId": "ae8c4164-a38a-469d-9365-ca22d43833e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgnoeyheat\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Taehyeong\\_DACON\\DACON_235910\\wandb\\run-20220621_181001-3o0poz97</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/gnoeyheat/DACON_235910/runs/3o0poz97\" target=\"_blank\">cRT</a></strong> to <a href=\"https://wandb.ai/gnoeyheat/DACON_235910\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>respiratory_condition</th>\n",
       "      <th>fever_or_muscle_pain</th>\n",
       "      <th>covid19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2.7372453e-09, -1.0615647e-08, 5.2142607e-08,...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  id  age  gender  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   1   24  female   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   2   51    male   \n",
       "2  [2.7372453e-09, -1.0615647e-08, 5.2142607e-08,...   3   22    male   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   4   29  female   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   5   23    male   \n",
       "\n",
       "   respiratory_condition  fever_or_muscle_pain  covid19  \n",
       "0                      0                     1        0  \n",
       "1                      0                     0        0  \n",
       "2                      0                     0        0  \n",
       "3                      1                     0        0  \n",
       "4                      0                     0        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras import layers\n",
    "\n",
    "import librosa\n",
    "from audiomentations import SpecCompose, SpecFrequencyMask\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"DACON_235910\", name=\"cRT\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"cRT\")\n",
    "parser.add_argument('--feature', default=\"melspec\", type=str) # mfcc or melspec\n",
    "parser.add_argument('--pretrained_model', default=\"efficientnetb0\", type=str)\n",
    "parser.add_argument('--resize_size', default=224, type=int)\n",
    "parser.add_argument('--sampling_rate', default=16000, type=int)\n",
    "# parser.add_argument('--frequency_mask', default=0, type=float)\n",
    "parser.add_argument('--optimizer', default=\"sgd\", type=str) # sgd or adam\n",
    "parser.add_argument('--loss', default=\"bc\", type=str) # bc or fl\n",
    "parser.add_argument('--learning_rate', default=0.001, type=float)\n",
    "parser.add_argument('--batch_size', default=32, type=int)\n",
    "parser.add_argument('--epochs', default=100, type=int)\n",
    "parser.add_argument('--cv', default=10, type=int)\n",
    "parser.add_argument('--seed', default=1011, type=int)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "wandb.config.update(args)\n",
    "\n",
    "feature = args.feature\n",
    "pretrained_model = args.pretrained_model\n",
    "resize_size = args.resize_size\n",
    "sampling_rate = args.sampling_rate\n",
    "# frequency_mask = args.frequency_mask\n",
    "optimizer = args.optimizer\n",
    "loss = args.loss\n",
    "learning_rate = args.learning_rate\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.epochs\n",
    "cv = args.cv\n",
    "seed = args.seed\n",
    "\n",
    "def set_seeds(seed=seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# augment = SpecCompose([SpecFrequencyMask(p=frequency_mask)])\n",
    "    \n",
    "with open('data/train_df.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "with open('data/test_df.pkl', 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.91958\n",
       "1    0.08042\n",
       "Name: covid19, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"covid19\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"data/train_data.csv\")\n",
    "# test_df = pd.read_csv(\"data/test_data.csv\")\n",
    "\n",
    "# train_folder = \"data/train/\"\n",
    "# test_folder = \"data/test/\"\n",
    "\n",
    "# def dataset(folder, df):\n",
    "#     dataset = []\n",
    "#     for uid in tqdm(df['id']):\n",
    "#         path = os.path.join(folder, str(uid).zfill(5)+'.wav')\n",
    "#         y, sr = librosa.load(path, sr=sampling_rate)\n",
    "#         y = librosa.util.normalize(y)\n",
    "#         dataset.append([y])\n",
    "#     dataset = pd.DataFrame(dataset, columns=['data'])\n",
    "#     dataset = pd.concat([dataset, df], axis=1)\n",
    "#     return dataset\n",
    "\n",
    "# train_df = dataset(train_folder, train_df)\n",
    "# test_df = dataset(test_folder, test_df)\n",
    "\n",
    "# with open('train_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "# with open('test_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLr-znikdl4b"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2744,
     "status": "ok",
     "timestamp": 1655181967331,
     "user": {
      "displayName": "‍김태형[ 대학원석·박사통합과정재학 / 산업경영공학과 ]",
      "userId": "00288066936238655028"
     },
     "user_tz": -540
    },
    "id": "QhMtoag0S8OM",
    "outputId": "2ac9cf2d-01a5-4205-f921-52e5ca8e4911"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3805/3805 [04:25<00:00, 14.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5732/5732 [05:44<00:00, 16.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3805, 224, 224, 3), (3805,), (5732, 224, 224, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_dataset(data):\n",
    "\n",
    "    frame_length = 0.025\n",
    "    frame_stride = 0.010\n",
    "\n",
    "    input_nfft = int(round(sampling_rate*frame_length))\n",
    "    input_stride = int(round(sampling_rate*frame_stride))\n",
    "\n",
    "    extracted_features = []\n",
    "    for i in tqdm(data):\n",
    "        temp_S = []\n",
    "        for nfft, stride in zip([input_nfft, input_nfft*4, input_nfft],\n",
    "                                [input_stride, input_stride, input_stride*4]):\n",
    "            if feature == \"mfcc\":\n",
    "                S = librosa.feature.mfcc(y=i,\n",
    "                                         sr=sampling_rate,\n",
    "                                         n_mfcc=40,\n",
    "                                         n_fft=nfft,\n",
    "                                         hop_length=stride)\n",
    "            elif feature == \"melspec\":\n",
    "                S = librosa.feature.melspectrogram(y=i,\n",
    "                                                   sr=sampling_rate,\n",
    "                                                   n_mels=128,\n",
    "                                                   n_fft=nfft,\n",
    "                                                   hop_length=stride)\n",
    "                S = librosa.power_to_db(S, ref=np.max)\n",
    "            S = tf.image.resize(S[:, :, np.newaxis], (resize_size, resize_size))\n",
    "            temp_S.append(S[:, :, 0])\n",
    "        S = np.stack(temp_S, axis=2)\n",
    "        extracted_features.append(S)\n",
    "    return extracted_features\n",
    "\n",
    "X = np.array(preprocess_dataset(train_df[\"data\"]))\n",
    "X_test = np.array(preprocess_dataset(test_df[\"data\"]))\n",
    "y = train_df[\"covid19\"]\n",
    "\n",
    "X.shape, y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5732, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_feature(df):\n",
    "    temp = df.copy()\n",
    "    temp[\"condition1\"] = temp[\"respiratory_condition\"] + temp[\"fever_or_muscle_pain\"]\n",
    "    temp[\"condition2\"] = temp[\"respiratory_condition\"] * temp[\"fever_or_muscle_pain\"]\n",
    "    temp = temp.drop([\"id\", \"age\", \"gender\", \"respiratory_condition\", \"fever_or_muscle_pain\"], axis=1)\n",
    "    return temp\n",
    "\n",
    "train_df = preprocess_feature(train_df)\n",
    "test_df = preprocess_feature(test_df)\n",
    "\n",
    "X_test_tab = test_df[[\"condition1\", \"condition2\"]].values\n",
    "\n",
    "X_test_tab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mtlHyQhgAoN"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhXTtjxTTlss",
    "outputId": "7ca4889d-0322-4d75-ae76-33a37b41f868"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 50s 257ms/step - loss: 0.3696 - val_loss: 0.8882 - _timestamp: 1655803284.0000 - _runtime: 683.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 26s 239ms/step - loss: 0.2924 - val_loss: 0.5796 - _timestamp: 1655803312.0000 - _runtime: 711.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 0.2711 - val_loss: 0.4486 - _timestamp: 1655803339.0000 - _runtime: 738.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 26s 239ms/step - loss: 0.2572 - val_loss: 0.3666 - _timestamp: 1655803365.0000 - _runtime: 764.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2480 - val_loss: 0.4127 - _timestamp: 1655803392.0000 - _runtime: 791.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 0.2358 - val_loss: 0.2961 - _timestamp: 1655803418.0000 - _runtime: 817.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2373 - val_loss: 0.3029 - _timestamp: 1655803444.0000 - _runtime: 843.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2339 - val_loss: 0.3204 - _timestamp: 1655803470.0000 - _runtime: 869.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.2275 - val_loss: 0.3064 - _timestamp: 1655803495.0000 - _runtime: 894.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2332 - val_loss: 0.3054 - _timestamp: 1655803520.0000 - _runtime: 919.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 0.2285 - val_loss: 0.3039 - _timestamp: 1655803546.0000 - _runtime: 945.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2315 - val_loss: 0.3030 - _timestamp: 1655803571.0000 - _runtime: 970.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2318 - val_loss: 0.3030 - _timestamp: 1655803596.0000 - _runtime: 995.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 0.2283 - val_loss: 0.3029 - _timestamp: 1655803622.0000 - _runtime: 1021.0000\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2330 - val_loss: 0.3030 - _timestamp: 1655803647.0000 - _runtime: 1046.0000\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2355 - val_loss: 0.3028 - _timestamp: 1655803673.0000 - _runtime: 1072.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 247ms/step - loss: 1.0288 - val_loss: 0.2964 - _timestamp: 1655803685.0000 - _runtime: 1084.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.0143 - val_loss: 0.2980 - _timestamp: 1655803687.0000 - _runtime: 1086.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.9532 - val_loss: 0.3008 - _timestamp: 1655803690.0000 - _runtime: 1089.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.9366 - val_loss: 0.3051 - _timestamp: 1655803692.0000 - _runtime: 1091.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.9052 - val_loss: 0.3106 - _timestamp: 1655803694.0000 - _runtime: 1093.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.8650 - val_loss: 0.3179 - _timestamp: 1655803697.0000 - _runtime: 1096.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 104ms/step - loss: 0.8287 - val_loss: 0.3253 - _timestamp: 1655803699.0000 - _runtime: 1098.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 0.7910 - val_loss: 0.3339 - _timestamp: 1655803701.0000 - _runtime: 1100.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 114ms/step - loss: 0.7713 - val_loss: 0.3429 - _timestamp: 1655803703.0000 - _runtime: 1102.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 0.7589 - val_loss: 0.3530 - _timestamp: 1655803706.0000 - _runtime: 1105.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.7368 - val_loss: 0.3623 - _timestamp: 1655803708.0000 - _runtime: 1107.0000\n",
      "idx:1, f1:0.5587574085428163, threshold:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [08:30, 510.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 36s 256ms/step - loss: 0.3829 - val_loss: 0.6040 - _timestamp: 1655803796.0000 - _runtime: 1195.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 25s 237ms/step - loss: 0.2918 - val_loss: 0.3535 - _timestamp: 1655803823.0000 - _runtime: 1222.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.2720 - val_loss: 0.3996 - _timestamp: 1655803848.0000 - _runtime: 1247.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 24s 229ms/step - loss: 0.2605 - val_loss: 0.3027 - _timestamp: 1655803874.0000 - _runtime: 1273.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2501 - val_loss: 0.3128 - _timestamp: 1655803900.0000 - _runtime: 1299.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 25s 235ms/step - loss: 0.2425 - val_loss: 0.2779 - _timestamp: 1655803925.0000 - _runtime: 1324.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 0.2363 - val_loss: 0.2867 - _timestamp: 1655803951.0000 - _runtime: 1350.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 0.2296 - val_loss: 0.2767 - _timestamp: 1655803977.0000 - _runtime: 1376.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 25s 237ms/step - loss: 0.2260 - val_loss: 0.2626 - _timestamp: 1655804004.0000 - _runtime: 1403.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2324 - val_loss: 0.2668 - _timestamp: 1655804030.0000 - _runtime: 1429.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.2306 - val_loss: 0.2695 - _timestamp: 1655804056.0000 - _runtime: 1455.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2295 - val_loss: 0.2702 - _timestamp: 1655804081.0000 - _runtime: 1480.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 24s 228ms/step - loss: 0.2277 - val_loss: 0.2703 - _timestamp: 1655804107.0000 - _runtime: 1506.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2279 - val_loss: 0.2704 - _timestamp: 1655804132.0000 - _runtime: 1531.0000\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2299 - val_loss: 0.2705 - _timestamp: 1655804157.0000 - _runtime: 1556.0000\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2317 - val_loss: 0.2703 - _timestamp: 1655804183.0000 - _runtime: 1582.0000\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2310 - val_loss: 0.2701 - _timestamp: 1655804208.0000 - _runtime: 1607.0000\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2328 - val_loss: 0.2705 - _timestamp: 1655804234.0000 - _runtime: 1633.0000\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2268 - val_loss: 0.2700 - _timestamp: 1655804259.0000 - _runtime: 1658.0000\n",
      "Epoch 1/100\n",
      " 6/18 [=========>....................] - ETA: 0s - loss: 0.9657WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0537s vs `on_train_batch_end` time: 0.1176s). Check your callbacks.\n",
      "18/18 [==============================] - 10s 245ms/step - loss: 0.9777 - val_loss: 0.2623 - _timestamp: 1655804271.0000 - _runtime: 1670.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.9738 - val_loss: 0.2622 - _timestamp: 1655804275.0000 - _runtime: 1674.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.9433 - val_loss: 0.2630 - _timestamp: 1655804277.0000 - _runtime: 1676.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.9041 - val_loss: 0.2645 - _timestamp: 1655804280.0000 - _runtime: 1679.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 0.8780 - val_loss: 0.2669 - _timestamp: 1655804282.0000 - _runtime: 1681.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.8327 - val_loss: 0.2701 - _timestamp: 1655804284.0000 - _runtime: 1683.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.8208 - val_loss: 0.2741 - _timestamp: 1655804286.0000 - _runtime: 1685.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 114ms/step - loss: 0.8034 - val_loss: 0.2787 - _timestamp: 1655804289.0000 - _runtime: 1688.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 0.7942 - val_loss: 0.2843 - _timestamp: 1655804291.0000 - _runtime: 1690.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.7889 - val_loss: 0.2907 - _timestamp: 1655804293.0000 - _runtime: 1692.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.7436 - val_loss: 0.2975 - _timestamp: 1655804295.0000 - _runtime: 1694.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.7353 - val_loss: 0.3042 - _timestamp: 1655804298.0000 - _runtime: 1697.0000\n",
      "idx:2, f1:0.5775560224089636, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [18:19, 556.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 35s 251ms/step - loss: 0.3747 - val_loss: 0.6671 - _timestamp: 1655804371.0000 - _runtime: 1770.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 26s 243ms/step - loss: 0.2862 - val_loss: 0.4985 - _timestamp: 1655804399.0000 - _runtime: 1798.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.2660 - val_loss: 0.3716 - _timestamp: 1655804425.0000 - _runtime: 1824.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.2545 - val_loss: 0.2963 - _timestamp: 1655804451.0000 - _runtime: 1850.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2427 - val_loss: 0.3035 - _timestamp: 1655804477.0000 - _runtime: 1876.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2366 - val_loss: 0.3004 - _timestamp: 1655804503.0000 - _runtime: 1902.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.2377 - val_loss: 0.2962 - _timestamp: 1655804529.0000 - _runtime: 1928.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.2288 - val_loss: 0.3102 - _timestamp: 1655804555.0000 - _runtime: 1954.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.2293 - val_loss: 0.3021 - _timestamp: 1655804581.0000 - _runtime: 1980.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 25s 231ms/step - loss: 0.2283 - val_loss: 0.3052 - _timestamp: 1655804607.0000 - _runtime: 2006.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.2230 - val_loss: 0.3061 - _timestamp: 1655804633.0000 - _runtime: 2032.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 25s 230ms/step - loss: 0.2291 - val_loss: 0.3063 - _timestamp: 1655804659.0000 - _runtime: 2058.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 24s 228ms/step - loss: 0.2288 - val_loss: 0.3061 - _timestamp: 1655804684.0000 - _runtime: 2083.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 25s 229ms/step - loss: 0.2240 - val_loss: 0.3062 - _timestamp: 1655804710.0000 - _runtime: 2109.0000\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2291 - val_loss: 0.3061 - _timestamp: 1655804736.0000 - _runtime: 2135.0000\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.2245 - val_loss: 0.3061 - _timestamp: 1655804762.0000 - _runtime: 2161.0000\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 24s 228ms/step - loss: 0.2250 - val_loss: 0.3063 - _timestamp: 1655804787.0000 - _runtime: 2186.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 229ms/step - loss: 1.1313 - val_loss: 0.2938 - _timestamp: 1655804799.0000 - _runtime: 2198.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 3s 146ms/step - loss: 1.0860 - val_loss: 0.2908 - _timestamp: 1655804802.0000 - _runtime: 2201.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 1.0263 - val_loss: 0.2891 - _timestamp: 1655804805.0000 - _runtime: 2204.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 0.9793 - val_loss: 0.2888 - _timestamp: 1655804808.0000 - _runtime: 2207.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.9129 - val_loss: 0.2902 - _timestamp: 1655804810.0000 - _runtime: 2209.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.9019 - val_loss: 0.2932 - _timestamp: 1655804813.0000 - _runtime: 2212.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.8686 - val_loss: 0.2977 - _timestamp: 1655804815.0000 - _runtime: 2214.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.8378 - val_loss: 0.3037 - _timestamp: 1655804817.0000 - _runtime: 2216.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 0.7933 - val_loss: 0.3109 - _timestamp: 1655804819.0000 - _runtime: 2218.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.7828 - val_loss: 0.3187 - _timestamp: 1655804821.0000 - _runtime: 2220.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.7530 - val_loss: 0.3279 - _timestamp: 1655804824.0000 - _runtime: 2223.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.7395 - val_loss: 0.3379 - _timestamp: 1655804826.0000 - _runtime: 2225.0000\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.7117 - val_loss: 0.3484 - _timestamp: 1655804828.0000 - _runtime: 2227.0000\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.6980 - val_loss: 0.3583 - _timestamp: 1655804831.0000 - _runtime: 2230.0000\n",
      "idx:3, f1:0.5355276907001045, threshold:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [27:13, 546.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 36s 249ms/step - loss: 0.3824 - val_loss: 0.8051 - _timestamp: 1655804905.0000 - _runtime: 2304.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 25s 236ms/step - loss: 0.2933 - val_loss: 0.4073 - _timestamp: 1655804932.0000 - _runtime: 2331.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 25s 231ms/step - loss: 0.2754 - val_loss: 0.3009 - _timestamp: 1655804958.0000 - _runtime: 2357.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2640 - val_loss: 0.3078 - _timestamp: 1655804984.0000 - _runtime: 2383.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2525 - val_loss: 0.3099 - _timestamp: 1655805009.0000 - _runtime: 2408.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 25s 230ms/step - loss: 0.2403 - val_loss: 0.2953 - _timestamp: 1655805035.0000 - _runtime: 2434.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 24s 229ms/step - loss: 0.2417 - val_loss: 0.2870 - _timestamp: 1655805061.0000 - _runtime: 2460.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 0.2348 - val_loss: 0.3061 - _timestamp: 1655805087.0000 - _runtime: 2486.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.2389 - val_loss: 0.2899 - _timestamp: 1655805112.0000 - _runtime: 2511.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 0.2305 - val_loss: 0.2900 - _timestamp: 1655805137.0000 - _runtime: 2536.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2316 - val_loss: 0.2902 - _timestamp: 1655805163.0000 - _runtime: 2562.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2320 - val_loss: 0.2901 - _timestamp: 1655805188.0000 - _runtime: 2587.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2310 - val_loss: 0.2899 - _timestamp: 1655805214.0000 - _runtime: 2613.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2322 - val_loss: 0.2897 - _timestamp: 1655805239.0000 - _runtime: 2638.0000\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2320 - val_loss: 0.2899 - _timestamp: 1655805265.0000 - _runtime: 2664.0000\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2328 - val_loss: 0.2898 - _timestamp: 1655805291.0000 - _runtime: 2690.0000\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 0.2316 - val_loss: 0.2897 - _timestamp: 1655805316.0000 - _runtime: 2715.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 228ms/step - loss: 1.0925 - val_loss: 0.2864 - _timestamp: 1655805327.0000 - _runtime: 2726.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 3s 150ms/step - loss: 1.0597 - val_loss: 0.2862 - _timestamp: 1655805330.0000 - _runtime: 2729.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 122ms/step - loss: 1.0112 - val_loss: 0.2871 - _timestamp: 1655805332.0000 - _runtime: 2731.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 114ms/step - loss: 0.9789 - val_loss: 0.2895 - _timestamp: 1655805335.0000 - _runtime: 2734.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 0.9518 - val_loss: 0.2930 - _timestamp: 1655805337.0000 - _runtime: 2736.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.8947 - val_loss: 0.2976 - _timestamp: 1655805339.0000 - _runtime: 2738.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.8702 - val_loss: 0.3034 - _timestamp: 1655805341.0000 - _runtime: 2740.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.8440 - val_loss: 0.3108 - _timestamp: 1655805344.0000 - _runtime: 2743.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 0.8085 - val_loss: 0.3186 - _timestamp: 1655805346.0000 - _runtime: 2745.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 0.7984 - val_loss: 0.3272 - _timestamp: 1655805348.0000 - _runtime: 2747.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.7498 - val_loss: 0.3356 - _timestamp: 1655805350.0000 - _runtime: 2749.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 2s 123ms/step - loss: 0.7500 - val_loss: 0.3445 - _timestamp: 1655805353.0000 - _runtime: 2752.0000\n",
      "idx:4, f1:0.5206489349961372, threshold:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [35:54, 536.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 34s 246ms/step - loss: 0.3778 - val_loss: 0.6297 - _timestamp: 1655805426.0000 - _runtime: 2825.0000\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 25s 230ms/step - loss: 0.2891 - val_loss: 0.4891 - _timestamp: 1655805452.0000 - _runtime: 2851.0000\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 25s 229ms/step - loss: 0.2665 - val_loss: 0.3508 - _timestamp: 1655805478.0000 - _runtime: 2877.0000\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 25s 230ms/step - loss: 0.2641 - val_loss: 0.3336 - _timestamp: 1655805504.0000 - _runtime: 2903.0000\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 25s 231ms/step - loss: 0.2505 - val_loss: 0.2874 - _timestamp: 1655805530.0000 - _runtime: 2929.0000\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 0.2414 - val_loss: 0.3041 - _timestamp: 1655805555.0000 - _runtime: 2954.0000\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.2356 - val_loss: 0.2886 - _timestamp: 1655805581.0000 - _runtime: 2980.0000\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2290 - val_loss: 0.3013 - _timestamp: 1655805606.0000 - _runtime: 3005.0000\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 0.2267 - val_loss: 0.3070 - _timestamp: 1655805631.0000 - _runtime: 3030.0000\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2277 - val_loss: 0.3064 - _timestamp: 1655805656.0000 - _runtime: 3055.0000\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2317 - val_loss: 0.3070 - _timestamp: 1655805682.0000 - _runtime: 3081.0000\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 0.2325 - val_loss: 0.3074 - _timestamp: 1655805707.0000 - _runtime: 3106.0000\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 24s 221ms/step - loss: 0.2314 - val_loss: 0.3075 - _timestamp: 1655805733.0000 - _runtime: 3132.0000\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 24s 227ms/step - loss: 0.2353 - val_loss: 0.3079 - _timestamp: 1655805758.0000 - _runtime: 3157.0000\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 0.2301 - val_loss: 0.3078 - _timestamp: 1655805784.0000 - _runtime: 3183.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 289ms/step - loss: 1.1581 - val_loss: 0.2871 - _timestamp: 1655805796.0000 - _runtime: 3195.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 1.1461 - val_loss: 0.2880 - _timestamp: 1655805798.0000 - _runtime: 3197.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.2452 - val_loss: 0.2913 - _timestamp: 1655805800.0000 - _runtime: 3199.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.9927 - val_loss: 0.2967 - _timestamp: 1655805803.0000 - _runtime: 3202.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.9631 - val_loss: 0.3040 - _timestamp: 1655805805.0000 - _runtime: 3204.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 0.9061 - val_loss: 0.3130 - _timestamp: 1655805807.0000 - _runtime: 3206.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 105ms/step - loss: 0.8781 - val_loss: 0.3241 - _timestamp: 1655805809.0000 - _runtime: 3208.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 0.8357 - val_loss: 0.3362 - _timestamp: 1655805811.0000 - _runtime: 3210.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.8303 - val_loss: 0.3501 - _timestamp: 1655805813.0000 - _runtime: 3212.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 0.7756 - val_loss: 0.3645 - _timestamp: 1655805816.0000 - _runtime: 3215.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 0.7596 - val_loss: 0.3781 - _timestamp: 1655805818.0000 - _runtime: 3217.0000\n",
      "idx:5, f1:0.522931031604254, threshold:0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [43:39, 510.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 35s 257ms/step - loss: 0.3733 - val_loss: 0.7416 - _timestamp: 1655805891.0000 - _runtime: 3290.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 25s 234ms/step - loss: 0.2861 - val_loss: 0.5288 - _timestamp: 1655805918.0000 - _runtime: 3317.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 25s 233ms/step - loss: 0.2708 - val_loss: 0.4190 - _timestamp: 1655805945.0000 - _runtime: 3344.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 25s 236ms/step - loss: 0.2562 - val_loss: 0.3260 - _timestamp: 1655805972.0000 - _runtime: 3371.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 26s 241ms/step - loss: 0.2456 - val_loss: 0.3027 - _timestamp: 1655805999.0000 - _runtime: 3398.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2387 - val_loss: 0.3064 - _timestamp: 1655806025.0000 - _runtime: 3424.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2359 - val_loss: 0.3150 - _timestamp: 1655806051.0000 - _runtime: 3450.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 25s 233ms/step - loss: 0.2331 - val_loss: 0.2839 - _timestamp: 1655806078.0000 - _runtime: 3477.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 26s 237ms/step - loss: 0.2272 - val_loss: 0.2767 - _timestamp: 1655806105.0000 - _runtime: 3504.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2283 - val_loss: 0.2789 - _timestamp: 1655806131.0000 - _runtime: 3530.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2275 - val_loss: 0.2796 - _timestamp: 1655806157.0000 - _runtime: 3556.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2337 - val_loss: 0.2798 - _timestamp: 1655806183.0000 - _runtime: 3582.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 25s 229ms/step - loss: 0.2292 - val_loss: 0.2789 - _timestamp: 1655806209.0000 - _runtime: 3608.0000\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2319 - val_loss: 0.2793 - _timestamp: 1655806236.0000 - _runtime: 3635.0000\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 25s 230ms/step - loss: 0.2311 - val_loss: 0.2797 - _timestamp: 1655806262.0000 - _runtime: 3661.0000\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 25s 229ms/step - loss: 0.2274 - val_loss: 0.2798 - _timestamp: 1655806288.0000 - _runtime: 3687.0000\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 25s 231ms/step - loss: 0.2327 - val_loss: 0.2791 - _timestamp: 1655806314.0000 - _runtime: 3713.0000\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 25s 230ms/step - loss: 0.2285 - val_loss: 0.2788 - _timestamp: 1655806341.0000 - _runtime: 3740.0000\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 25s 230ms/step - loss: 0.2297 - val_loss: 0.2787 - _timestamp: 1655806367.0000 - _runtime: 3766.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 245ms/step - loss: 0.8998 - val_loss: 0.2767 - _timestamp: 1655806380.0000 - _runtime: 3779.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.8839 - val_loss: 0.2770 - _timestamp: 1655806382.0000 - _runtime: 3781.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 0.8429 - val_loss: 0.2776 - _timestamp: 1655806385.0000 - _runtime: 3784.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 0.8546 - val_loss: 0.2787 - _timestamp: 1655806387.0000 - _runtime: 3786.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.8321 - val_loss: 0.2801 - _timestamp: 1655806389.0000 - _runtime: 3788.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.8211 - val_loss: 0.2819 - _timestamp: 1655806392.0000 - _runtime: 3791.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 0.7938 - val_loss: 0.2843 - _timestamp: 1655806394.0000 - _runtime: 3793.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.7623 - val_loss: 0.2869 - _timestamp: 1655806396.0000 - _runtime: 3795.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.7580 - val_loss: 0.2896 - _timestamp: 1655806399.0000 - _runtime: 3798.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.7671 - val_loss: 0.2928 - _timestamp: 1655806401.0000 - _runtime: 3800.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 0.7534 - val_loss: 0.2962 - _timestamp: 1655806404.0000 - _runtime: 3803.0000\n",
      "idx:6, f1:0.5834855681402996, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [53:26, 536.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 35s 258ms/step - loss: 0.3869 - val_loss: 0.4772 - _timestamp: 1655806476.0000 - _runtime: 3875.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 25s 235ms/step - loss: 0.2921 - val_loss: 0.4378 - _timestamp: 1655806503.0000 - _runtime: 3902.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 25s 236ms/step - loss: 0.2762 - val_loss: 0.3326 - _timestamp: 1655806530.0000 - _runtime: 3929.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 25s 234ms/step - loss: 0.2577 - val_loss: 0.2824 - _timestamp: 1655806557.0000 - _runtime: 3956.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2511 - val_loss: 0.3008 - _timestamp: 1655806583.0000 - _runtime: 3982.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 25s 236ms/step - loss: 0.2468 - val_loss: 0.2712 - _timestamp: 1655806609.0000 - _runtime: 4008.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2363 - val_loss: 0.2751 - _timestamp: 1655806635.0000 - _runtime: 4034.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 25s 230ms/step - loss: 0.2333 - val_loss: 0.2796 - _timestamp: 1655806662.0000 - _runtime: 4061.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 24s 227ms/step - loss: 0.2355 - val_loss: 0.2810 - _timestamp: 1655806687.0000 - _runtime: 4086.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2326 - val_loss: 0.2822 - _timestamp: 1655806713.0000 - _runtime: 4112.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2318 - val_loss: 0.2814 - _timestamp: 1655806739.0000 - _runtime: 4138.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 25s 229ms/step - loss: 0.2368 - val_loss: 0.2812 - _timestamp: 1655806766.0000 - _runtime: 4165.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 25s 230ms/step - loss: 0.2343 - val_loss: 0.2809 - _timestamp: 1655806792.0000 - _runtime: 4191.0000\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2316 - val_loss: 0.2806 - _timestamp: 1655806819.0000 - _runtime: 4218.0000\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 25s 229ms/step - loss: 0.2343 - val_loss: 0.2806 - _timestamp: 1655806846.0000 - _runtime: 4245.0000\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2334 - val_loss: 0.2811 - _timestamp: 1655806872.0000 - _runtime: 4271.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 10s 263ms/step - loss: 1.1592 - val_loss: 0.2701 - _timestamp: 1655806885.0000 - _runtime: 4284.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 3s 145ms/step - loss: 1.1301 - val_loss: 0.2694 - _timestamp: 1655806888.0000 - _runtime: 4287.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 1.0923 - val_loss: 0.2699 - _timestamp: 1655806890.0000 - _runtime: 4289.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 1.0361 - val_loss: 0.2717 - _timestamp: 1655806893.0000 - _runtime: 4292.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.9654 - val_loss: 0.2750 - _timestamp: 1655806895.0000 - _runtime: 4294.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 119ms/step - loss: 0.9542 - val_loss: 0.2797 - _timestamp: 1655806897.0000 - _runtime: 4296.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.9101 - val_loss: 0.2859 - _timestamp: 1655806900.0000 - _runtime: 4299.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 0.8903 - val_loss: 0.2932 - _timestamp: 1655806902.0000 - _runtime: 4301.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 114ms/step - loss: 0.8602 - val_loss: 0.3019 - _timestamp: 1655806904.0000 - _runtime: 4303.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.8101 - val_loss: 0.3111 - _timestamp: 1655806907.0000 - _runtime: 4306.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 0.8028 - val_loss: 0.3214 - _timestamp: 1655806909.0000 - _runtime: 4308.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 0.7929 - val_loss: 0.3324 - _timestamp: 1655806911.0000 - _runtime: 4310.0000\n",
      "idx:7, f1:0.5657142857142857, threshold:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [1:01:52, 526.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 35s 245ms/step - loss: 0.3976 - val_loss: 0.6744 - _timestamp: 1655806986.0000 - _runtime: 4385.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 25s 233ms/step - loss: 0.2825 - val_loss: 0.3429 - _timestamp: 1655807012.0000 - _runtime: 4411.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 25s 229ms/step - loss: 0.2712 - val_loss: 0.3080 - _timestamp: 1655807038.0000 - _runtime: 4437.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.2579 - val_loss: 0.3194 - _timestamp: 1655807064.0000 - _runtime: 4463.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 25s 232ms/step - loss: 0.2444 - val_loss: 0.2928 - _timestamp: 1655807091.0000 - _runtime: 4490.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2396 - val_loss: 0.3138 - _timestamp: 1655807117.0000 - _runtime: 4516.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2320 - val_loss: 0.3187 - _timestamp: 1655807142.0000 - _runtime: 4541.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.2357 - val_loss: 0.3060 - _timestamp: 1655807168.0000 - _runtime: 4567.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2262 - val_loss: 0.3045 - _timestamp: 1655807194.0000 - _runtime: 4593.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2310 - val_loss: 0.3039 - _timestamp: 1655807220.0000 - _runtime: 4619.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2239 - val_loss: 0.3036 - _timestamp: 1655807246.0000 - _runtime: 4645.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2299 - val_loss: 0.3041 - _timestamp: 1655807272.0000 - _runtime: 4671.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2297 - val_loss: 0.3038 - _timestamp: 1655807297.0000 - _runtime: 4696.0000\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 25s 229ms/step - loss: 0.2271 - val_loss: 0.3037 - _timestamp: 1655807324.0000 - _runtime: 4723.0000\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2259 - val_loss: 0.3043 - _timestamp: 1655807350.0000 - _runtime: 4749.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 233ms/step - loss: 1.1086 - val_loss: 0.2923 - _timestamp: 1655807361.0000 - _runtime: 4760.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 3s 170ms/step - loss: 1.0839 - val_loss: 0.2922 - _timestamp: 1655807364.0000 - _runtime: 4763.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.0267 - val_loss: 0.2932 - _timestamp: 1655807366.0000 - _runtime: 4765.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 107ms/step - loss: 1.0083 - val_loss: 0.2953 - _timestamp: 1655807368.0000 - _runtime: 4767.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 0.9697 - val_loss: 0.2985 - _timestamp: 1655807371.0000 - _runtime: 4770.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 112ms/step - loss: 0.9244 - val_loss: 0.3025 - _timestamp: 1655807373.0000 - _runtime: 4772.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 0.8981 - val_loss: 0.3079 - _timestamp: 1655807375.0000 - _runtime: 4774.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.8673 - val_loss: 0.3139 - _timestamp: 1655807378.0000 - _runtime: 4777.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 0.8438 - val_loss: 0.3208 - _timestamp: 1655807380.0000 - _runtime: 4779.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 124ms/step - loss: 0.8181 - val_loss: 0.3289 - _timestamp: 1655807382.0000 - _runtime: 4781.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 116ms/step - loss: 0.7948 - val_loss: 0.3369 - _timestamp: 1655807385.0000 - _runtime: 4784.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 2s 125ms/step - loss: 0.7769 - val_loss: 0.3455 - _timestamp: 1655807387.0000 - _runtime: 4786.0000\n",
      "idx:8, f1:0.5211566520758721, threshold:0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [1:09:49, 510.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 35s 249ms/step - loss: 0.3794 - val_loss: 0.5337 - _timestamp: 1655807460.0000 - _runtime: 4859.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 26s 237ms/step - loss: 0.2951 - val_loss: 0.3981 - _timestamp: 1655807487.0000 - _runtime: 4886.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 25s 235ms/step - loss: 0.2758 - val_loss: 0.2831 - _timestamp: 1655807514.0000 - _runtime: 4913.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2609 - val_loss: 0.3217 - _timestamp: 1655807540.0000 - _runtime: 4939.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 25s 229ms/step - loss: 0.2548 - val_loss: 0.3006 - _timestamp: 1655807566.0000 - _runtime: 4965.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2413 - val_loss: 0.3029 - _timestamp: 1655807592.0000 - _runtime: 4991.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.2387 - val_loss: 0.2963 - _timestamp: 1655807618.0000 - _runtime: 5017.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2349 - val_loss: 0.2988 - _timestamp: 1655807644.0000 - _runtime: 5043.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2274 - val_loss: 0.2927 - _timestamp: 1655807670.0000 - _runtime: 5069.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2308 - val_loss: 0.2901 - _timestamp: 1655807696.0000 - _runtime: 5095.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2336 - val_loss: 0.2886 - _timestamp: 1655807722.0000 - _runtime: 5121.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 25s 230ms/step - loss: 0.2332 - val_loss: 0.2896 - _timestamp: 1655807748.0000 - _runtime: 5147.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 25s 230ms/step - loss: 0.2333 - val_loss: 0.2892 - _timestamp: 1655807774.0000 - _runtime: 5173.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 242ms/step - loss: 1.1249 - val_loss: 0.2866 - _timestamp: 1655807785.0000 - _runtime: 5184.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 1.0843 - val_loss: 0.2944 - _timestamp: 1655807787.0000 - _runtime: 5186.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 1.0284 - val_loss: 0.3055 - _timestamp: 1655807790.0000 - _runtime: 5189.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.9685 - val_loss: 0.3206 - _timestamp: 1655807792.0000 - _runtime: 5191.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.9199 - val_loss: 0.3375 - _timestamp: 1655807794.0000 - _runtime: 5193.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 0.8855 - val_loss: 0.3566 - _timestamp: 1655807796.0000 - _runtime: 5195.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 109ms/step - loss: 0.8281 - val_loss: 0.3781 - _timestamp: 1655807799.0000 - _runtime: 5198.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.8140 - val_loss: 0.3986 - _timestamp: 1655807801.0000 - _runtime: 5200.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.7960 - val_loss: 0.4184 - _timestamp: 1655807803.0000 - _runtime: 5202.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 114ms/step - loss: 0.7901 - val_loss: 0.4406 - _timestamp: 1655807806.0000 - _runtime: 5205.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 125ms/step - loss: 0.7695 - val_loss: 0.4604 - _timestamp: 1655807808.0000 - _runtime: 5207.0000\n",
      "idx:9, f1:0.5353247984826932, threshold:0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [1:16:48, 482.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 35s 247ms/step - loss: 0.3795 - val_loss: 0.7201 - _timestamp: 1655807879.0000 - _runtime: 5278.0000\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 25s 233ms/step - loss: 0.2904 - val_loss: 0.4027 - _timestamp: 1655807905.0000 - _runtime: 5304.0000\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 25s 232ms/step - loss: 0.2776 - val_loss: 0.3092 - _timestamp: 1655807932.0000 - _runtime: 5331.0000\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 24s 221ms/step - loss: 0.2613 - val_loss: 0.3239 - _timestamp: 1655807957.0000 - _runtime: 5356.0000\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 24s 221ms/step - loss: 0.2493 - val_loss: 0.3277 - _timestamp: 1655807982.0000 - _runtime: 5381.0000\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 25s 232ms/step - loss: 0.2472 - val_loss: 0.2713 - _timestamp: 1655808009.0000 - _runtime: 5408.0000\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2321 - val_loss: 0.3003 - _timestamp: 1655808034.0000 - _runtime: 5433.0000\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 24s 222ms/step - loss: 0.2359 - val_loss: 0.2933 - _timestamp: 1655808060.0000 - _runtime: 5459.0000\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2360 - val_loss: 0.2901 - _timestamp: 1655808085.0000 - _runtime: 5484.0000\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 24s 222ms/step - loss: 0.2305 - val_loss: 0.2894 - _timestamp: 1655808111.0000 - _runtime: 5510.0000\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2307 - val_loss: 0.2884 - _timestamp: 1655808136.0000 - _runtime: 5535.0000\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 25s 227ms/step - loss: 0.2349 - val_loss: 0.2882 - _timestamp: 1655808162.0000 - _runtime: 5561.0000\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 24s 223ms/step - loss: 0.2342 - val_loss: 0.2879 - _timestamp: 1655808188.0000 - _runtime: 5587.0000\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 24s 222ms/step - loss: 0.2325 - val_loss: 0.2878 - _timestamp: 1655808213.0000 - _runtime: 5612.0000\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2347 - val_loss: 0.2873 - _timestamp: 1655808239.0000 - _runtime: 5638.0000\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 24s 222ms/step - loss: 0.2334 - val_loss: 0.2875 - _timestamp: 1655808264.0000 - _runtime: 5663.0000\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 9s 232ms/step - loss: 1.1138 - val_loss: 0.2722 - _timestamp: 1655808275.0000 - _runtime: 5674.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 2s 114ms/step - loss: 1.0539 - val_loss: 0.2746 - _timestamp: 1655808278.0000 - _runtime: 5677.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 2s 106ms/step - loss: 1.0184 - val_loss: 0.2782 - _timestamp: 1655808280.0000 - _runtime: 5679.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 2s 108ms/step - loss: 0.9727 - val_loss: 0.2828 - _timestamp: 1655808282.0000 - _runtime: 5681.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.9362 - val_loss: 0.2884 - _timestamp: 1655808285.0000 - _runtime: 5684.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 2s 118ms/step - loss: 0.9100 - val_loss: 0.2953 - _timestamp: 1655808287.0000 - _runtime: 5686.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 2s 110ms/step - loss: 0.8936 - val_loss: 0.3031 - _timestamp: 1655808289.0000 - _runtime: 5688.0000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 0.8300 - val_loss: 0.3114 - _timestamp: 1655808292.0000 - _runtime: 5691.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.8283 - val_loss: 0.3208 - _timestamp: 1655808294.0000 - _runtime: 5693.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 2s 115ms/step - loss: 0.8108 - val_loss: 0.3307 - _timestamp: 1655808296.0000 - _runtime: 5695.0000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 0.7912 - val_loss: 0.3417 - _timestamp: 1655808299.0000 - _runtime: 5698.0000\n",
      "idx:10, f1:0.58260644827809, threshold:0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [1:25:00, 510.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_macro-f1:  0.5503708840943518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validations = []\n",
    "thresholds = []\n",
    "predictions = []\n",
    "\n",
    "idx=0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cv)\n",
    "for train_index, val_index in tqdm(skf.split(X, y)):\n",
    "    \n",
    "    idx+=1\n",
    "\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train_tab = train_df[[\"condition1\", \"condition2\"]].values[train_index]\n",
    "    X_val_tab = train_df[[\"condition1\", \"condition2\"]].values[val_index]\n",
    "    \n",
    "    train_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(((X_train, X_train_tab), y_train))\n",
    "        .shuffle(len(X_train))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    val_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(((X_val, X_val_tab), y_val))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    if pretrained_model == \"efficientnetb0\":\n",
    "        encoder = tf.keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            pooling='avg',\n",
    "        )\n",
    "\n",
    "    inp = tf.keras.Input(shape=(resize_size, resize_size, 3))\n",
    "    tab = tf.keras.Input(shape=(X_test_tab.shape[1],))\n",
    "    x = encoder(inp)\n",
    "    x = layers.Concatenate()([x, tab])\n",
    "    oup = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(inputs=[inp, tab], outputs=oup)\n",
    "\n",
    "    lr = tf.keras.optimizers.schedules.CosineDecay(learning_rate, decay_steps=1000)\n",
    "    if optimizer == \"adam\":\n",
    "        optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optim = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "        \n",
    "    label_smoothing=0\n",
    "    loss_function = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optim,\n",
    "        loss=loss_function,\n",
    "    )\n",
    "    \n",
    "    checkpoint_filepath=f\"load_model/{parser.description}_{idx}_1stage\"\n",
    "\n",
    "    checkpoint_callback = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint_callback, WandbCallback()],\n",
    "    )\n",
    "    \n",
    "    X_train = np.concatenate((X_train[np.where(y_train==0, True, False)][:y_train.sum()],\n",
    "                              X_train[np.where(y_train==1, True, False)]))\n",
    "    X_train_tab = np.concatenate((X_train_tab[np.where(y_train==0, True, False)][:y_train.sum()],\n",
    "                                  X_train_tab[np.where(y_train==1, True, False)]))\n",
    "    y_train = np.concatenate((y_train[np.where(y_train==0, True, False)][:y_train.sum()],\n",
    "                              y_train[np.where(y_train==1, True, False)]))\n",
    "\n",
    "    train_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(((X_train, X_train_tab), y_train))\n",
    "        .shuffle(len(X_train))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    encoder.trainable = False\n",
    "    \n",
    "    lr = tf.keras.optimizers.schedules.CosineDecay(learning_rate*0.1, decay_steps=1000)\n",
    "    if optimizer == \"adam\":\n",
    "        optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optim = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optim,\n",
    "        loss=loss_function,\n",
    "    )\n",
    "    \n",
    "    checkpoint_filepath=f\"load_model/{parser.description}_{idx}_2stage\"\n",
    "\n",
    "    checkpoint_callback = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint_callback, WandbCallback()],\n",
    "    )\n",
    "\n",
    "    max_f1 = 0\n",
    "    threshold = 0\n",
    "    for temp_threshold in np.linspace(0.05, 0.95, 19):\n",
    "        temp_f1 = f1_score(y_val, np.where(model.predict(val_ds)>temp_threshold, 1, 0), average=\"macro\")\n",
    "        if temp_f1 > max_f1:\n",
    "            max_f1 = temp_f1\n",
    "            threshold = temp_threshold\n",
    "    \n",
    "    print(f\"idx:{idx}, f1:{max_f1}, threshold:{threshold}\")\n",
    "    \n",
    "    validations.append(max_f1)\n",
    "    thresholds.append(threshold)\n",
    "    predictions.append(model.predict([X_test, X_test_tab]))\n",
    "\n",
    "val_f1 = np.mean(validations, axis=0)\n",
    "\n",
    "print(\"validation_macro-f1: \", val_f1)\n",
    "wandb.log({'validation_macro-f1': val_f1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7vNprtvVIb0"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Rb1j87j7k3l9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.974878\n",
       "1    0.025122\n",
       "Name: covid19, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = np.mean(thresholds)\n",
    "test_df[\"covid19\"] = np.where(np.mean(predictions, axis=0)>threshold, 1, 0)\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['covid19'] = test_df['covid19']\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "test_df['covid19'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOI2a3K41SRHmr0VYqCJIVd",
   "collapsed_sections": [],
   "mount_file_id": "12SyNXKXsgbk5c855KhTFRgLEogv2xCNZ",
   "name": "2. Baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
